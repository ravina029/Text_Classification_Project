{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d40805",
   "metadata": {},
   "source": [
    "# 03_Feature_Engineering_and_Modeling\n",
    "\n",
    "PhD-level notebook: TF-IDF baselines + DistilBERT fine-tuning for IMDB sentiment classification.\n",
    "\n",
    "Saves outputs (models, vectorizers, metrics) to the `results/` folder at project root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce868d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "python -c \"import sys; print('Python', sys.version)\"\n",
    "# Install datasets if missing (transformers assumed installed)\n",
    "python -c \"import importlib; importlib.import_module('datasets')\" 2>/dev/null || pip install --quiet datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da11d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths (adjust if your project root differs)\n",
    "PREPROCESSED_PATH = Path('/Users/ravina/Desktop/Text_Classification_Project/data/processed/imdb_preprocessed.csv')\n",
    "RESULTS_DIR = Path('/Users/ravina/Desktop/Text_Classification_Project/results')\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Preprocessed path:', PREPROCESSED_PATH)\n",
    "print('Results dir:', RESULTS_DIR)\n",
    "\n",
    "assert PREPROCESSED_PATH.exists(), f'Preprocessed file not found at {PREPROCESSED_PATH}'\n",
    "df = pd.read_csv(PREPROCESSED_PATH)\n",
    "print('Loaded rows:', len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce36f3a",
   "metadata": {},
   "source": [
    "## Quick checks and train/test split\n",
    "Ensure your dataframe contains a processed text column. The notebook will try `processed_text`, `final_review`, `clean_text`, then `review`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose text column\n",
    "for col in ['processed_text','final_review','clean_text','review']:\n",
    "    if col in df.columns:\n",
    "        TEXT_COL = col\n",
    "        break\n",
    "print('Using text column:', TEXT_COL)\n",
    "\n",
    "if df['sentiment'].dtype == 'object':\n",
    "    df['sentiment'] = df['sentiment'].map({'neg':0,'pos':1})\n",
    "\n",
    "X = df[TEXT_COL].astype(str)\n",
    "y = df['sentiment'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train samples:', len(X_train), 'Test samples:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c483e",
   "metadata": {},
   "source": [
    "## TF-IDF vectorization and Classical ML Baselines\n",
    "We vectorize with TF-IDF and train Logistic Regression, MultinomialNB, LinearSVC, RandomForest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23957b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "vec = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_train_vec = vec.fit_transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)\n",
    "print('TF-IDF shape:', X_train_vec.shape)\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print('\\nTraining', name)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    preds = model.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    try:\n",
    "        prob = model.predict_proba(X_test_vec)[:,1]\n",
    "        auc = roc_auc_score(y_test, prob)\n",
    "    except Exception:\n",
    "        auc = None\n",
    "    print(name, 'Accuracy:', acc, 'AUC:', auc)\n",
    "    print(classification_report(y_test, preds))\n",
    "    results[name] = {'model': model, 'accuracy': acc, 'auc': auc}\n",
    "    joblib.dump(model, RESULTS_DIR / f'{name}.joblib')\n",
    "\n",
    "# save vectorizer\n",
    "joblib.dump(vec, RESULTS_DIR / 'tfidf_vectorizer.joblib')\n",
    "print('\\nSaved models and vectorizer to', RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a24851",
   "metadata": {},
   "source": [
    "### Feature importance from Logistic Regression (top features)\n",
    "We print top positive and negative coefficients from Logistic Regression for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc82483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clf = results['LogisticRegression']['model']\n",
    "if hasattr(clf, 'coef_'):\n",
    "    coefs = clf.coef_[0]\n",
    "    top_pos_idx = np.argsort(coefs)[-30:][::-1]\n",
    "    top_neg_idx = np.argsort(coefs)[:30]\n",
    "    feature_names = np.array(vec.get_feature_names_out())\n",
    "    print('Top positive features:')\n",
    "    print(feature_names[top_pos_idx])\n",
    "    print('\\nTop negative features:')\n",
    "    print(feature_names[top_neg_idx])\n",
    "else:\n",
    "    print('Model has no coef_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "summary = {k: {'accuracy': v['accuracy'], 'auc': v['auc']} for k,v in results.items()}\n",
    "with open(RESULTS_DIR / 'classical_results_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print('Saved classical results summary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3549c",
   "metadata": {},
   "source": [
    "## DistilBERT Fine-tuning (Hugging Face)\n",
    "This section fine-tunes DistilBERT. **Warning:** fine-tuning on CPU is slow. For research, use GPU. We run 1 epoch here for a quick experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c91247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# Build HF Datasets\n",
    "train_df = pd.DataFrame({'text': X_train.values, 'label': y_train.values})\n",
    "test_df = pd.DataFrame({'text': X_test.values, 'label': y_test.values})\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "train_ds = train_ds.remove_columns(['text'])\n",
    "train_ds.set_format(type='torch', columns=['input_ids','attention_mask','label'])\n",
    "\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "test_ds = test_ds.remove_columns(['text'])\n",
    "test_ds.set_format(type='torch', columns=['input_ids','attention_mask','label'])\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(RESULTS_DIR / 'hf_outputs'),\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    logging_steps=100,\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "# compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train (may be slow on CPU)\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate and save\n",
    "metrics = trainer.evaluate()\n",
    "print('DistilBERT eval metrics:', metrics)\n",
    "trainer.save_model(RESULTS_DIR / 'hf_outputs' / 'distilbert_imdb')\n",
    "print('Saved DistilBERT to', RESULTS_DIR / 'hf_outputs' / 'distilbert_imdb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd803e39",
   "metadata": {},
   "source": [
    "## Comparison & Next Steps\n",
    "- Compare classical results (saved in `results/classical_results_summary.json`) with DistilBERT metrics printed above.\n",
    "- For full transformer training, use a GPU (Colab or cloud). Consider distillation for production.\n",
    "\n",
    "Files saved to `results/`:\n",
    "- TF-IDF vectorizer: `results/tfidf_vectorizer.joblib`\n",
    "- Classical models: `results/{model}.joblib`\n",
    "- Classical summary: `results/classical_results_summary.json`\n",
    "- DistilBERT outputs: `results/hf_outputs/distilbert_imdb`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
